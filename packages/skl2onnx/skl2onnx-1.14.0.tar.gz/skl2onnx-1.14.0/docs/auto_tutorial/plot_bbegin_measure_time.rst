
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial\plot_bbegin_measure_time.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_bbegin_measure_time.py:


Benchmark ONNX conversion
=========================

.. index:: benchmark

Example :ref:`l-simple-deploy-1` converts a simple model.
This example takes a similar example but on random data
and compares the processing time required by each option
to compute predictions.

.. contents::
    :local:


Training a pipeline
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 21-50

.. code-block:: default

    import numpy
    from pandas import DataFrame
    from tqdm import tqdm
    from sklearn import config_context
    from sklearn.datasets import make_regression
    from sklearn.ensemble import (
        GradientBoostingRegressor, RandomForestRegressor,
        VotingRegressor)
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from mlprodict.onnxrt import OnnxInference
    from onnxruntime import InferenceSession
    from skl2onnx import to_onnx
    from skl2onnx.tutorial import measure_time


    N = 11000
    X, y = make_regression(N, n_features=10)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, train_size=0.01)
    print("Train shape", X_train.shape)
    print("Test shape", X_test.shape)

    reg1 = GradientBoostingRegressor(random_state=1)
    reg2 = RandomForestRegressor(random_state=1)
    reg3 = LinearRegression()
    ereg = VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])
    ereg.fit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Train shape (110, 10)
    Test shape (10890, 10)


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-13" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>VotingRegressor(estimators=[(&#x27;gb&#x27;, GradientBoostingRegressor(random_state=1)),
                                (&#x27;rf&#x27;, RandomForestRegressor(random_state=1)),
                                (&#x27;lr&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-43" type="checkbox" ><label for="sk-estimator-id-43" class="sk-toggleable__label sk-toggleable__label-arrow">VotingRegressor</label><div class="sk-toggleable__content"><pre>VotingRegressor(estimators=[(&#x27;gb&#x27;, GradientBoostingRegressor(random_state=1)),
                                (&#x27;rf&#x27;, RandomForestRegressor(random_state=1)),
                                (&#x27;lr&#x27;, LinearRegression())])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><label>gb</label></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-44" type="checkbox" ><label for="sk-estimator-id-44" class="sk-toggleable__label sk-toggleable__label-arrow">GradientBoostingRegressor</label><div class="sk-toggleable__content"><pre>GradientBoostingRegressor(random_state=1)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><label>rf</label></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-45" type="checkbox" ><label for="sk-estimator-id-45" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestRegressor</label><div class="sk-toggleable__content"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><label>lr</label></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-46" type="checkbox" ><label for="sk-estimator-id-46" class="sk-toggleable__label sk-toggleable__label-arrow">LinearRegression</label><div class="sk-toggleable__content"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 51-60

Measure the processing time
+++++++++++++++++++++++++++

We use function :func:`skl2onnx.tutorial.measure_time`.
The page about `assume_finite <https://scikit-learn.org/
stable/modules/generated/sklearn.config_context.html>`_
may be useful if you need to optimize the prediction.
We measure the processing time per observation whether
or not an observation belongs to a batch or is a single one.

.. GENERATED FROM PYTHON SOURCE LINES 60-77

.. code-block:: default


    sizes = [(1, 50), (10, 50), (1000, 10), (10000, 5)]

    with config_context(assume_finite=True):
        obs = []
        for batch_size, repeat in tqdm(sizes):
            context = {"ereg": ereg, 'X': X_test[:batch_size]}
            mt = measure_time(
                "ereg.predict(X)", context, div_by_number=True,
                number=10, repeat=repeat)
            mt['size'] = context['X'].shape[0]
            mt['mean_obs'] = mt['average'] / mt['size']
            obs.append(mt)

    df_skl = DataFrame(obs)
    df_skl





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                            | 0/4 [00:00<?, ?it/s]     25%|#####################                                                               | 1/4 [00:02<00:06,  2.33s/it]     50%|##########################################                                          | 2/4 [00:04<00:04,  2.41s/it]     75%|###############################################################                     | 3/4 [00:07<00:02,  2.56s/it]    100%|####################################################################################| 4/4 [00:12<00:00,  3.63s/it]    100%|####################################################################################| 4/4 [00:12<00:00,  3.20s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>mean_obs</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.004647</td>
          <td>0.000407</td>
          <td>0.004471</td>
          <td>0.007398</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.004647</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.004946</td>
          <td>0.000096</td>
          <td>0.004840</td>
          <td>0.005276</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.000495</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.027328</td>
          <td>0.003031</td>
          <td>0.023683</td>
          <td>0.033310</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000027</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.105363</td>
          <td>0.004518</td>
          <td>0.097339</td>
          <td>0.109609</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000011</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 78-79

Graphe.

.. GENERATED FROM PYTHON SOURCE LINES 79-83

.. code-block:: default


    df_skl.set_index('size')[['mean_obs']].plot(
        title="scikit-learn", logx=True, logy=True)




.. image-sg:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_001.png
   :alt: scikit-learn
   :srcset: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-89

ONNX runtime
++++++++++++

The same is done with the two ONNX runtime
available.

.. GENERATED FROM PYTHON SOURCE LINES 89-127

.. code-block:: default


    onx = to_onnx(ereg, X_train[:1].astype(numpy.float32),
                  target_opset=14)
    sess = InferenceSession(onx.SerializeToString())
    oinf = OnnxInference(onx, runtime="python_compiled")

    obs = []
    for batch_size, repeat in tqdm(sizes):

        # scikit-learn
        context = {"ereg": ereg, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt = measure_time(
            "ereg.predict(X)", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['size'] = context['X'].shape[0]
        mt['skl'] = mt['average'] / mt['size']

        # onnxruntime
        context = {"sess": sess, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "sess.run(None, {'X': X})[0]", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['ort'] = mt2['average'] / mt['size']

        # mlprodict
        context = {"oinf": oinf, 'X': X_test[:batch_size].astype(numpy.float32)}
        mt2 = measure_time(
            "oinf.run({'X': X})['variable']", context, div_by_number=True,
            number=10, repeat=repeat)
        mt['pyrt'] = mt2['average'] / mt['size']

        # end
        obs.append(mt)


    df = DataFrame(obs)
    df





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|                                                                                            | 0/4 [00:00<?, ?it/s]     25%|#####################                                                               | 1/4 [00:02<00:07,  2.38s/it]     50%|##########################################                                          | 2/4 [00:04<00:04,  2.39s/it]     75%|###############################################################                     | 3/4 [00:07<00:02,  2.65s/it]    100%|####################################################################################| 4/4 [00:14<00:00,  4.25s/it]    100%|####################################################################################| 4/4 [00:14<00:00,  3.61s/it]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>average</th>
          <th>deviation</th>
          <th>min_exec</th>
          <th>max_exec</th>
          <th>repeat</th>
          <th>number</th>
          <th>size</th>
          <th>skl</th>
          <th>ort</th>
          <th>pyrt</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.004582</td>
          <td>0.000388</td>
          <td>0.004421</td>
          <td>0.007251</td>
          <td>50</td>
          <td>10</td>
          <td>1</td>
          <td>0.004582</td>
          <td>5.071820e-05</td>
          <td>0.000107</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.004537</td>
          <td>0.000358</td>
          <td>0.004364</td>
          <td>0.006595</td>
          <td>50</td>
          <td>10</td>
          <td>10</td>
          <td>0.000454</td>
          <td>1.060444e-05</td>
          <td>0.000015</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.026251</td>
          <td>0.002954</td>
          <td>0.022403</td>
          <td>0.031852</td>
          <td>10</td>
          <td>10</td>
          <td>1000</td>
          <td>0.000026</td>
          <td>1.056859e-06</td>
          <td>0.000002</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.107268</td>
          <td>0.003260</td>
          <td>0.101123</td>
          <td>0.110290</td>
          <td>5</td>
          <td>10</td>
          <td>10000</td>
          <td>0.000011</td>
          <td>7.389192e-07</td>
          <td>0.000002</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 128-129

Graph.

.. GENERATED FROM PYTHON SOURCE LINES 129-134

.. code-block:: default


    df.set_index('size')[['skl', 'ort', 'pyrt']].plot(
        title="Average prediction time per runtime",
        logx=True, logy=True)




.. image-sg:: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_002.png
   :alt: Average prediction time per runtime
   :srcset: /auto_tutorial/images/sphx_glr_plot_bbegin_measure_time_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 135-141

:epkg:`ONNX` runtimes are much faster than :epkg:`scikit-learn`
to predict one observation. :epkg:`scikit-learn` is optimized
for training, for batch prediction. That explains why
:epkg:`scikit-learn` and ONNX runtimes seem to converge
for big batches. They use similar implementation,
parallelization and languages (:epkg:`C++`, :epkg:`openmp`).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  31.902 seconds)


.. _sphx_glr_download_auto_tutorial_plot_bbegin_measure_time.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_tutorial/plot_bbegin_measure_time.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bbegin_measure_time.py <plot_bbegin_measure_time.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bbegin_measure_time.ipynb <plot_bbegin_measure_time.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
