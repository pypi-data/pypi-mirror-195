
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples\plot_intermediate_outputs.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_intermediate_outputs.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_intermediate_outputs.py:


Walk through intermediate outputs
=================================

We reuse the example :ref:`example-complex-pipeline` and
walk through intermediates outputs. It is very likely a converted
model gives different outputs or fails due to a custom
converter which is not correctly implemented.
One option is to look into the output of every node of the
ONNX graph.

.. contents::
    :local:

Create and train a complex pipeline
+++++++++++++++++++++++++++++++++++

We reuse the pipeline implemented in example
`Column Transformer with Mixed Types
<https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py>`_.
There is one change because
`ONNX-ML Imputer
<https://github.com/onnx/onnx/blob/master/docs/
Operators-ml.md#ai.onnx.ml.Imputer>`_
does not handle string type. This cannot be part of the final ONNX pipeline
and must be removed. Look for comment starting with ``---`` below.

.. GENERATED FROM PYTHON SOURCE LINES 31-92

.. code-block:: default

    import skl2onnx
    import onnx
    import sklearn
    import matplotlib.pyplot as plt
    import os
    from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer
    from skl2onnx.helpers.onnx_helper import select_model_inputs_outputs
    from skl2onnx.helpers.onnx_helper import save_onnx_model
    from skl2onnx.helpers.onnx_helper import enumerate_model_node_outputs
    from skl2onnx.helpers.onnx_helper import load_onnx_model
    import numpy
    import onnxruntime as rt
    from skl2onnx import convert_sklearn
    import pprint
    from skl2onnx.common.data_types import (
        FloatTensorType, StringTensorType, Int64TensorType)
    import numpy as np
    import pandas as pd
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split

    titanic_url = ('https://raw.githubusercontent.com/amueller/'
                   'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')
    data = pd.read_csv(titanic_url)
    X = data.drop('survived', axis=1)
    y = data['survived']

    # SimpleImputer on string is not available
    # for string in ONNX-ML specifications.
    # So we do it beforehand.
    for cat in ['embarked', 'sex', 'pclass']:
        X[cat].fillna('missing', inplace=True)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    numeric_features = ['age', 'fare']
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())])

    categorical_features = ['embarked', 'sex', 'pclass']
    categorical_transformer = Pipeline(steps=[
        # --- SimpleImputer is not available for strings in ONNX-ML specifications.
        # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features),
        ])

    clf = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', LogisticRegression(solver='lbfgs'))])

    clf.fit(X_train, y_train)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,
                     ColumnTransformer(transformers=[(&#x27;num&#x27;,
                                                      Pipeline(steps=[(&#x27;imputer&#x27;,
                                                                       SimpleImputer(strategy=&#x27;median&#x27;)),
                                                                      (&#x27;scaler&#x27;,
                                                                       StandardScaler())]),
                                                      [&#x27;age&#x27;, &#x27;fare&#x27;]),
                                                     (&#x27;cat&#x27;,
                                                      Pipeline(steps=[(&#x27;onehot&#x27;,
                                                                       OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),
                                                      [&#x27;embarked&#x27;, &#x27;sex&#x27;,
                                                       &#x27;pclass&#x27;])])),
                    (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-16" type="checkbox" ><label for="sk-estimator-id-16" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,
                     ColumnTransformer(transformers=[(&#x27;num&#x27;,
                                                      Pipeline(steps=[(&#x27;imputer&#x27;,
                                                                       SimpleImputer(strategy=&#x27;median&#x27;)),
                                                                      (&#x27;scaler&#x27;,
                                                                       StandardScaler())]),
                                                      [&#x27;age&#x27;, &#x27;fare&#x27;]),
                                                     (&#x27;cat&#x27;,
                                                      Pipeline(steps=[(&#x27;onehot&#x27;,
                                                                       OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),
                                                      [&#x27;embarked&#x27;, &#x27;sex&#x27;,
                                                       &#x27;pclass&#x27;])])),
                    (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-17" type="checkbox" ><label for="sk-estimator-id-17" class="sk-toggleable__label sk-toggleable__label-arrow">preprocessor: ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,
                                     Pipeline(steps=[(&#x27;imputer&#x27;,
                                                      SimpleImputer(strategy=&#x27;median&#x27;)),
                                                     (&#x27;scaler&#x27;, StandardScaler())]),
                                     [&#x27;age&#x27;, &#x27;fare&#x27;]),
                                    (&#x27;cat&#x27;,
                                     Pipeline(steps=[(&#x27;onehot&#x27;,
                                                      OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),
                                     [&#x27;embarked&#x27;, &#x27;sex&#x27;, &#x27;pclass&#x27;])])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-18" type="checkbox" ><label for="sk-estimator-id-18" class="sk-toggleable__label sk-toggleable__label-arrow">num</label><div class="sk-toggleable__content"><pre>[&#x27;age&#x27;, &#x27;fare&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox" ><label for="sk-estimator-id-19" class="sk-toggleable__label sk-toggleable__label-arrow">SimpleImputer</label><div class="sk-toggleable__content"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox" ><label for="sk-estimator-id-20" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-21" type="checkbox" ><label for="sk-estimator-id-21" class="sk-toggleable__label sk-toggleable__label-arrow">cat</label><div class="sk-toggleable__content"><pre>[&#x27;embarked&#x27;, &#x27;sex&#x27;, &#x27;pclass&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-22" type="checkbox" ><label for="sk-estimator-id-22" class="sk-toggleable__label sk-toggleable__label-arrow">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox" ><label for="sk-estimator-id-23" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 93-99

Define the inputs of the ONNX graph
+++++++++++++++++++++++++++++++++++

*sklearn-onnx* does not know the features used to train the model
but it needs to know which feature has which name.
We simply reuse the dataframe column definition.

.. GENERATED FROM PYTHON SOURCE LINES 99-101

.. code-block:: default

    print(X_train.dtypes)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    pclass         int64
    name          object
    sex           object
    age          float64
    sibsp          int64
    parch          int64
    ticket        object
    fare         float64
    cabin         object
    embarked      object
    boat          object
    body         float64
    home.dest     object
    dtype: object




.. GENERATED FROM PYTHON SOURCE LINES 102-103

After conversion.

.. GENERATED FROM PYTHON SOURCE LINES 103-124

.. code-block:: default



    def convert_dataframe_schema(df, drop=None):
        inputs = []
        for k, v in zip(df.columns, df.dtypes):
            if drop is not None and k in drop:
                continue
            if v == 'int64':
                t = Int64TensorType([None, 1])
            elif v == 'float64':
                t = FloatTensorType([None, 1])
            else:
                t = StringTensorType([None, 1])
            inputs.append((k, t))
        return inputs


    inputs = convert_dataframe_schema(X_train)

    pprint.pprint(inputs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [('pclass', Int64TensorType(shape=[None, 1])),
     ('name', StringTensorType(shape=[None, 1])),
     ('sex', StringTensorType(shape=[None, 1])),
     ('age', FloatTensorType(shape=[None, 1])),
     ('sibsp', Int64TensorType(shape=[None, 1])),
     ('parch', Int64TensorType(shape=[None, 1])),
     ('ticket', StringTensorType(shape=[None, 1])),
     ('fare', FloatTensorType(shape=[None, 1])),
     ('cabin', StringTensorType(shape=[None, 1])),
     ('embarked', StringTensorType(shape=[None, 1])),
     ('boat', StringTensorType(shape=[None, 1])),
     ('body', FloatTensorType(shape=[None, 1])),
     ('home.dest', StringTensorType(shape=[None, 1]))]




.. GENERATED FROM PYTHON SOURCE LINES 125-128

Merging single column into vectors is not
the most efficient way to compute the prediction.
It could be done before converting the pipeline into a graph.

.. GENERATED FROM PYTHON SOURCE LINES 130-132

Convert the pipeline into ONNX
++++++++++++++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 132-139

.. code-block:: default


    try:
        model_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs,
                                     target_opset=12)
    except Exception as e:
        print(e)








.. GENERATED FROM PYTHON SOURCE LINES 140-143

*scikit-learn* does implicit conversions when it can.
*sklearn-onnx* does not. The ONNX version of *OneHotEncoder*
must be applied on columns of the same type.

.. GENERATED FROM PYTHON SOURCE LINES 143-158

.. code-block:: default


    X_train['pclass'] = X_train['pclass'].astype(str)
    X_test['pclass'] = X_test['pclass'].astype(str)
    white_list = numeric_features + categorical_features
    to_drop = [c for c in X_train.columns if c not in white_list]
    inputs = convert_dataframe_schema(X_train, to_drop)

    model_onnx = convert_sklearn(clf, 'pipeline_titanic', inputs,
                                 target_opset=12)


    # And save.
    with open("pipeline_titanic.onnx", "wb") as f:
        f.write(model_onnx.SerializeToString())








.. GENERATED FROM PYTHON SOURCE LINES 159-165

Compare the predictions
+++++++++++++++++++++++

Final step, we need to ensure the converted model
produces the same predictions, labels and probabilities.
Let's start with *scikit-learn*.

.. GENERATED FROM PYTHON SOURCE LINES 165-169

.. code-block:: default


    print("predict", clf.predict(X_test[:5]))
    print("predict_proba", clf.predict_proba(X_test[:1]))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    predict [1 1 1 0 0]
    predict_proba [[0.2192673 0.7807327]]




.. GENERATED FROM PYTHON SOURCE LINES 170-179

Predictions with onnxruntime.
We need to remove the dropped columns and to change
the double vectors into float vectors as *onnxruntime*
does not support double floats.
*onnxruntime* does not accept *dataframe*.
inputs must be given as a list of dictionary.
Last detail, every column was described  not really as a vector
but as a matrix of one column which explains the last line
with the *reshape*.

.. GENERATED FROM PYTHON SOURCE LINES 179-187

.. code-block:: default


    X_test2 = X_test.drop(to_drop, axis=1)
    inputs = {c: X_test2[c].values for c in X_test2.columns}
    for c in numeric_features:
        inputs[c] = inputs[c].astype(np.float32)
    for k in inputs:
        inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))








.. GENERATED FROM PYTHON SOURCE LINES 188-189

We are ready to run *onnxruntime*.

.. GENERATED FROM PYTHON SOURCE LINES 189-196

.. code-block:: default


    sess = rt.InferenceSession("pipeline_titanic.onnx")
    pred_onx = sess.run(None, inputs)
    print("predict", pred_onx[0][:5])
    print("predict_proba", pred_onx[1][:1])






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    predict [1 1 1 0 0]
    predict_proba [{0: 0.09280234575271606, 1: 0.9071976542472839}]




.. GENERATED FROM PYTHON SOURCE LINES 197-204

Compute intermediate outputs
++++++++++++++++++++++++++++

Unfortunately, there is actually no way to ask
*onnxruntime* to retrieve the output of intermediate nodes.
We need to modifies the *ONNX* before it is given to *onnxruntime*.
Let's see first the list of intermediate output.

.. GENERATED FROM PYTHON SOURCE LINES 204-209

.. code-block:: default


    model_onnx = load_onnx_model("pipeline_titanic.onnx")
    for out in enumerate_model_node_outputs(model_onnx):
        print(out)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    sexout
    pclassout
    fare_cast
    age_cast
    embarkedout
    concat_result
    merged_columns
    variable2
    variable
    variable1
    variable2_cast
    variable1_cast
    transformed_column
    label
    probability_tensor
    probabilities
    output_label
    output_probability




.. GENERATED FROM PYTHON SOURCE LINES 210-216

Not that easy to tell which one is what as the *ONNX*
has more operators than the original *scikit-learn* pipelines.
The graph at :ref:`l-plot-complex-pipeline-graph`
helps up to find the outputs of both numerical
and textual pipeline: *variable1*, *variable2*.
Let's look into the numerical pipeline first.

.. GENERATED FROM PYTHON SOURCE LINES 216-220

.. code-block:: default


    num_onnx = select_model_inputs_outputs(model_onnx, 'variable1')
    save_onnx_model(num_onnx, "pipeline_titanic_numerical.onnx")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    b'\x08\x07\x12\x08skl2onnx\x1a\x041.13"\x07ai.onnx(\x002\x00:\xae\x04\n^\n\x08variable\x12\tvariable1\x1a\x06Scaler"\x06Scaler*\x15\n\x06offset=\x9c\xb4\xe8A=\x1d\x9c\x05B\xa0\x01\x06*\x14\n\x05scale=\xe7\xe3\xa4==^\xca\x99<\xa0\x01\x06:\nai.onnx.ml\n}\n\x0emerged_columns\x12\x08variable\x1a\x07Imputer"\x07Imputer*#\n\x14imputed_value_floats=\x00\x00\xe0A=gDgA\xa0\x01\x06*\x1e\n\x14replaced_value_float\x15\x00\x00\xc0\x7f\xa0\x01\x01:\nai.onnx.ml\nD\n\x08age_cast\n\tfare_cast\x12\x0emerged_columns\x1a\x06Concat"\x06Concat*\x0b\n\x04axis\x18\x01\xa0\x01\x02:\x00\n(\n\x03age\x12\x08age_cast\x1a\x04Cast"\x04Cast*\t\n\x02to\x18\x01\xa0\x01\x02:\x00\n+\n\x04fare\x12\tfare_cast\x1a\x05Cast1"\x04Cast*\t\n\x02to\x18\x01\xa0\x01\x02:\x00\x12\x10pipeline_titanic*\x1f\x08\x02\x10\x07:\x0b\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01\tB\x0cshape_tensorZ\x16\n\x06pclass\x12\x0c\n\n\x08\x08\x12\x06\n\x00\n\x02\x08\x01Z\x13\n\x03sex\x12\x0c\n\n\x08\x08\x12\x06\n\x00\n\x02\x08\x01Z\x13\n\x03age\x12\x0c\n\n\x08\x01\x12\x06\n\x00\n\x02\x08\x01Z\x14\n\x04fare\x12\x0c\n\n\x08\x01\x12\x06\n\x00\n\x02\x08\x01Z\x18\n\x08embarked\x12\x0c\n\n\x08\x08\x12\x06\n\x00\n\x02\x08\x01b\x0b\n\tvariable1B\x0e\n\nai.onnx.ml\x10\x01B\x04\n\x00\x10\x0b'



.. GENERATED FROM PYTHON SOURCE LINES 221-222

Let's compute the numerical features.

.. GENERATED FROM PYTHON SOURCE LINES 222-227

.. code-block:: default


    sess = rt.InferenceSession("pipeline_titanic_numerical.onnx")
    numX = sess.run(None, inputs)
    print("numerical features", numX[0][:1])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numerical features [[-0.32915154  2.218014  ]]




.. GENERATED FROM PYTHON SOURCE LINES 228-229

We do the same for the textual features.

.. GENERATED FROM PYTHON SOURCE LINES 229-237

.. code-block:: default


    print(model_onnx)
    text_onnx = select_model_inputs_outputs(model_onnx, 'variable2')
    save_onnx_model(text_onnx, "pipeline_titanic_textual.onnx")
    sess = rt.InferenceSession("pipeline_titanic_textual.onnx")
    numT = sess.run(None, inputs)
    print("textual features", numT[0][:1])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ir_version: 7
    producer_name: "skl2onnx"
    producer_version: "1.13"
    domain: "ai.onnx"
    model_version: 0
    doc_string: ""
    graph {
      node {
        input: "sex"
        output: "sexout"
        name: "OneHotEncoder1"
        op_type: "OneHotEncoder"
        attribute {
          name: "cats_strings"
          strings: "female"
          strings: "male"
          type: STRINGS
        }
        attribute {
          name: "zeros"
          i: 1
          type: INT
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "pclass"
        output: "pclassout"
        name: "OneHotEncoder2"
        op_type: "OneHotEncoder"
        attribute {
          name: "cats_strings"
          strings: "1"
          strings: "2"
          strings: "3"
          type: STRINGS
        }
        attribute {
          name: "zeros"
          i: 1
          type: INT
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "fare"
        output: "fare_cast"
        name: "Cast1"
        op_type: "Cast"
        attribute {
          name: "to"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "age"
        output: "age_cast"
        name: "Cast"
        op_type: "Cast"
        attribute {
          name: "to"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "embarked"
        output: "embarkedout"
        name: "OneHotEncoder"
        op_type: "OneHotEncoder"
        attribute {
          name: "cats_strings"
          strings: "C"
          strings: "Q"
          strings: "S"
          strings: "missing"
          type: STRINGS
        }
        attribute {
          name: "zeros"
          i: 1
          type: INT
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "embarkedout"
        input: "sexout"
        input: "pclassout"
        output: "concat_result"
        name: "Concat1"
        op_type: "Concat"
        attribute {
          name: "axis"
          i: 2
          type: INT
        }
        domain: ""
      }
      node {
        input: "age_cast"
        input: "fare_cast"
        output: "merged_columns"
        name: "Concat"
        op_type: "Concat"
        attribute {
          name: "axis"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "concat_result"
        input: "shape_tensor"
        output: "variable2"
        name: "Reshape"
        op_type: "Reshape"
        domain: ""
      }
      node {
        input: "merged_columns"
        output: "variable"
        name: "Imputer"
        op_type: "Imputer"
        attribute {
          name: "imputed_value_floats"
          floats: 28.0
          floats: 14.45419979095459
          type: FLOATS
        }
        attribute {
          name: "replaced_value_float"
          f: nan
          type: FLOAT
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "variable"
        output: "variable1"
        name: "Scaler"
        op_type: "Scaler"
        attribute {
          name: "offset"
          floats: 29.08818817138672
          floats: 33.4024543762207
          type: FLOATS
        }
        attribute {
          name: "scale"
          floats: 0.08051281422376633
          floats: 0.01877325400710106
          type: FLOATS
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "variable2"
        output: "variable2_cast"
        name: "Cast3"
        op_type: "Cast"
        attribute {
          name: "to"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "variable1"
        output: "variable1_cast"
        name: "Cast2"
        op_type: "Cast"
        attribute {
          name: "to"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "variable1_cast"
        input: "variable2_cast"
        output: "transformed_column"
        name: "Concat2"
        op_type: "Concat"
        attribute {
          name: "axis"
          i: 1
          type: INT
        }
        domain: ""
      }
      node {
        input: "transformed_column"
        output: "label"
        output: "probability_tensor"
        name: "LinearClassifier"
        op_type: "LinearClassifier"
        attribute {
          name: "classlabels_ints"
          ints: 0
          ints: 1
          type: INTS
        }
        attribute {
          name: "coefficients"
          floats: 0.43954846262931824
          floats: -0.035433121025562286
          floats: -0.2703384459018707
          floats: -0.02360350452363491
          floats: 0.38908761739730835
          floats: -0.09513344615697861
          floats: -1.2203079462051392
          floats: 1.220320224761963
          floats: -1.0099470615386963
          floats: -0.06721878796815872
          floats: 1.0771780014038086
          floats: -0.43954846262931824
          floats: 0.035433121025562286
          floats: 0.2703384459018707
          floats: 0.02360350452363491
          floats: -0.38908761739730835
          floats: 0.09513344615697861
          floats: 1.2203079462051392
          floats: -1.220320224761963
          floats: 1.0099470615386963
          floats: 0.06721878796815872
          floats: -1.0771780014038086
          type: FLOATS
        }
        attribute {
          name: "intercepts"
          floats: -0.21545174717903137
          floats: 0.21545174717903137
          type: FLOATS
        }
        attribute {
          name: "multi_class"
          i: 1
          type: INT
        }
        attribute {
          name: "post_transform"
          s: "LOGISTIC"
          type: STRING
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "probability_tensor"
        output: "probabilities"
        name: "Normalizer"
        op_type: "Normalizer"
        attribute {
          name: "norm"
          s: "L1"
          type: STRING
        }
        domain: "ai.onnx.ml"
      }
      node {
        input: "label"
        output: "output_label"
        name: "Cast4"
        op_type: "Cast"
        attribute {
          name: "to"
          i: 7
          type: INT
        }
        domain: ""
      }
      node {
        input: "probabilities"
        output: "output_probability"
        name: "ZipMap"
        op_type: "ZipMap"
        attribute {
          name: "classlabels_int64s"
          ints: 0
          ints: 1
          type: INTS
        }
        domain: "ai.onnx.ml"
      }
      name: "pipeline_titanic"
      initializer {
        dims: 2
        data_type: 7
        int64_data: -1
        int64_data: 9
        name: "shape_tensor"
      }
      input {
        name: "pclass"
        type {
          tensor_type {
            elem_type: 8
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
      input {
        name: "sex"
        type {
          tensor_type {
            elem_type: 8
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
      input {
        name: "age"
        type {
          tensor_type {
            elem_type: 1
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
      input {
        name: "fare"
        type {
          tensor_type {
            elem_type: 1
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
      input {
        name: "embarked"
        type {
          tensor_type {
            elem_type: 8
            shape {
              dim {
              }
              dim {
                dim_value: 1
              }
            }
          }
        }
      }
      output {
        name: "output_label"
        type {
          tensor_type {
            elem_type: 7
            shape {
              dim {
              }
            }
          }
        }
      }
      output {
        name: "output_probability"
        type {
          sequence_type {
            elem_type {
              map_type {
                key_type: 7
                value_type {
                  tensor_type {
                    elem_type: 1
                  }
                }
              }
            }
          }
        }
      }
    }
    opset_import {
      domain: "ai.onnx.ml"
      version: 1
    }
    opset_import {
      domain: ""
      version: 11
    }

    textual features [[0. 0. 1. 0. 1. 0. 1. 0. 0.]]




.. GENERATED FROM PYTHON SOURCE LINES 238-242

Display the sub-ONNX graph
++++++++++++++++++++++++++

Finally, let's see both subgraphs. First, numerical pipeline.

.. GENERATED FROM PYTHON SOURCE LINES 242-256

.. code-block:: default


    pydot_graph = GetPydotGraph(
        num_onnx.graph, name=num_onnx.graph.name, rankdir="TB",
        node_producer=GetOpNodeProducer(
            "docstring", color="yellow", fillcolor="yellow", style="filled"))
    pydot_graph.write_dot("pipeline_titanic_num.dot")

    os.system('dot -O -Gdpi=300 -Tpng pipeline_titanic_num.dot')

    image = plt.imread("pipeline_titanic_num.dot.png")
    fig, ax = plt.subplots(figsize=(40, 20))
    ax.imshow(image)
    ax.axis('off')




.. image-sg:: /auto_examples/images/sphx_glr_plot_intermediate_outputs_001.png
   :alt: plot intermediate outputs
   :srcset: /auto_examples/images/sphx_glr_plot_intermediate_outputs_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (-0.5, 4372.5, 1033.5, -0.5)



.. GENERATED FROM PYTHON SOURCE LINES 257-258

Then textual pipeline.

.. GENERATED FROM PYTHON SOURCE LINES 258-272

.. code-block:: default


    pydot_graph = GetPydotGraph(
        text_onnx.graph, name=text_onnx.graph.name, rankdir="TB",
        node_producer=GetOpNodeProducer(
            "docstring", color="yellow", fillcolor="yellow", style="filled"))
    pydot_graph.write_dot("pipeline_titanic_text.dot")

    os.system('dot -O -Gdpi=300 -Tpng pipeline_titanic_text.dot')

    image = plt.imread("pipeline_titanic_text.dot.png")
    fig, ax = plt.subplots(figsize=(40, 20))
    ax.imshow(image)
    ax.axis('off')




.. image-sg:: /auto_examples/images/sphx_glr_plot_intermediate_outputs_002.png
   :alt: plot intermediate outputs
   :srcset: /auto_examples/images/sphx_glr_plot_intermediate_outputs_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (-0.5, 7086.5, 1121.5, -0.5)



.. GENERATED FROM PYTHON SOURCE LINES 273-274

**Versions used for this example**

.. GENERATED FROM PYTHON SOURCE LINES 274-280

.. code-block:: default


    print("numpy:", numpy.__version__)
    print("scikit-learn:", sklearn.__version__)
    print("onnx: ", onnx.__version__)
    print("onnxruntime: ", rt.__version__)
    print("skl2onnx: ", skl2onnx.__version__)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    numpy: 1.23.2
    scikit-learn: 1.1.0
    onnx:  1.12.0
    onnxruntime:  1.12.1
    skl2onnx:  1.13





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  3.587 seconds)


.. _sphx_glr_download_auto_examples_plot_intermediate_outputs.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_examples/plot_intermediate_outputs.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_intermediate_outputs.py <plot_intermediate_outputs.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_intermediate_outputs.ipynb <plot_intermediate_outputs.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
